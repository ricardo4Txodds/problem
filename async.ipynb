{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca860143-0c5d-453b-b5bb-8a3e576be3a4",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "788a5e66-c206-4606-a7cb-ab1a4c3f7015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "044eed49-9ec7-42ff-b2d6-8ad22971acb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "nest_asyncio.apply()\n",
    "\n",
    "#assuming a csv file with white space between each url\n",
    "raw_list = pd.read_csv('url_list.txt', sep=\" \", header=None, names=['url', '#'])\n",
    "input_list = deque()\n",
    "output_list = []\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e972f0-ec3e-4238-9574-423eae1c64e0",
   "metadata": {},
   "source": [
    "### Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bbcce01-2be4-46f5-b4c5-7a1ef88c1d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_urls():       \n",
    "    #iterate all url's and add them to the stack\n",
    "    for index, row in raw_list.iterrows():\n",
    "        url = row['url']           \n",
    "        input_list.append(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafe2cac-9156-488e-ac18-01e8985ddeaf",
   "metadata": {},
   "source": [
    "### Consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a95f53-1711-499f-91f6-a451ebe83fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_links(): \n",
    "    \n",
    "          while input_list:\n",
    "            try:\n",
    "                r = await requests.get(input_list.pop()).text              \n",
    "            except Exception as e:\n",
    "                print(\"[ERROR] -> \", e)\n",
    "    \n",
    "        soup = bs(r, 'html.parser')\n",
    "        \n",
    "        for link in soup.find_all('a'):\n",
    "            hyper = str(link.get('href'))\n",
    "            \n",
    "            #ignoring the relative_paths\n",
    "            if not hyper.find(\"http://\") or not hyper.find(\"https://\"):                           \n",
    "                output_list.append(hyper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfda634e-2112-4950-9881-4432f9b2d7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main(): \n",
    "    task1 = asyncio.create_task(get_urls())\n",
    "    task2 = asyncio.create_task(get_links())\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fad1f7-3037-491d-a9d5-5b8080a0629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "try:\n",
    "    loop.run_until_complete(main())\n",
    "except Exception as e:\n",
    "    print(\"[ERROR] -> \", e)\n",
    "    \n",
    "duration = time.time() - start_time\n",
    "\n",
    "print(duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9006145-6a5b-40f2-81c5-6a7c2d96dd90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
